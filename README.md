# seq2seq-with-attention
An educational PyTorch implementation of sequence‑to‑sequence models with attention, trained on a synthetic reverse‑sequence task. Includes training scripts, loss/accuracy visualizations, and quantitative evaluation of how attention improves model performance.
